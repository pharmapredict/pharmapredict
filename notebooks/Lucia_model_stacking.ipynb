{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score,roc_curve, auc\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('../raw_data/wra_CT_PM_conclusions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['thera_count'] = df['Therapeutic area'].apply(lambda x: x.count(',') + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numerical= df.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df_numerical.drop(labels= 'Unnamed: 0', inplace=True, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Authorisation status', 'Orphan medicine', 'n_trials',\n",
       "       'status_not_yet_recruiting', 'status_recruiting',\n",
       "       'status_enrolling_by_invitation', 'status_active_not_recruiting',\n",
       "       'status_suspended', 'status_terminated', 'status_completed',\n",
       "       'status_withdrawn', 'status_unknown', 'org_fed', 'org_indiv',\n",
       "       'org_industry', 'org_network', 'org_nih', 'org_other', 'org_other_gov',\n",
       "       'phase_early_1', 'phase_not_applicable', 'phase_1', 'phase_2',\n",
       "       'phase_3', 'phase_4', 'pm_results', 'thera_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numerical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_list= df_numerical.columns[3:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for column in percent_list:\n",
    "    df_numerical[column]=((df_numerical[column]*100)/df_numerical['n_trials']).replace([np.inf, -np.inf, np.nan], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned=df_numerical[df_numerical['n_trials']< 3000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_list= ['org_industry',  'n_trials',  'phase_4',\n",
    "             'org_other', 'status_completed', 'status_recruiting',\n",
    "             'phase_3',  'pm_results', 'status_not_yet_recruiting',\n",
    "             'phase_2','Authorisation status', 'thera_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model=df_cleaned[top_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df_model.drop(labels='Authorisation status', axis=1)\n",
    "y=df_model['Authorisation status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_numericals= {'RandomForestClassifier()': RandomForestClassifier(bootstrap= False, max_depth= 12, max_features= 'auto', min_samples_leaf= 1, min_samples_split= 2, n_estimators= 100),\n",
    " 'KNeighborsClassifier()':KNeighborsClassifier(algorithm= 'auto', leaf_size=10, n_jobs= -1, n_neighbors= 5, p= 1, weights= 'distance'),\n",
    " 'MLPClassifier()': MLPClassifier(activation= 'tanh',alpha= 1e-05, early_stopping= True, hidden_layer_sizes= 250, learning_rate= 'invscaling', learning_rate_init= 0.01, max_iter= 3000, n_iter_no_change= 10, solver= 'lbfgs'),\n",
    " 'BernoulliNB()': BernoulliNB(alpha=0.1),\n",
    " 'ComplementNB()':ComplementNB(alpha=1.2) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForestClassifier()',\n",
       " 'KNeighborsClassifier()',\n",
       " 'MLPClassifier()',\n",
       " 'BernoulliNB()',\n",
       " 'ComplementNB()',\n",
       " 'TfIdf()']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list= list(optimized_numericals.keys())\n",
    "model_list.append('TfIdf()')\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state =1,test_size = 0.2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2692307692307692"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf= optimized_numericals['RandomForestClassifier()']\n",
    "\n",
    "clf1= model_rf.fit(X_train, y_train)\n",
    "\n",
    "y1_pred=clf1.predict(X_test)\n",
    "\n",
    "f1_score(y_test, y1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4109589041095891"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_kn= optimized_numericals['KNeighborsClassifier()']\n",
    "\n",
    "clf2= model_kn.fit(X_train, y_train)\n",
    "\n",
    "y2_pred=clf2.predict(X_test)\n",
    "\n",
    "f1_score(y_test, y2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.41025641025641024"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp= optimized_numericals['MLPClassifier()']\n",
    "clf3= model_mlp.fit(X_train, y_train)\n",
    "y3_pred=clf3.predict(X_test)\n",
    "f1_score(y_test, y3_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3658536585365854"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bern= optimized_numericals['BernoulliNB()']\n",
    "clf4= model_bern.fit(X_train, y_train)\n",
    "y4_pred=clf4.predict(X_test)\n",
    "f1_score(y_test, y4_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25000000000000006"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comp= optimized_numericals['ComplementNB()']\n",
    "clf5= model_comp.fit(X_train, y_train)\n",
    "y5_pred=clf5.predict(X_test)\n",
    "f1_score(y_test, y5_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1363,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text=df['conclusions']\n",
    "X_text=X_text.replace([np.nan], \" \")\n",
    "y_text=df['Authorisation status']\n",
    "y_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df = 0.8, min_df=0.5, max_features = 50, ngram_range=(1, 1))\n",
    "X_text_vect = vectorizer.fit_transform(X_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vectors = X_text_vect.toarray()\n",
    "\n",
    "model_text= RandomForestClassifier(max_depth=2, random_state=0, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(X_vectors,y_text, random_state =1,test_size = 0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.471311475409836"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6= model_text.fit(X_text_train, y_text_train)\n",
    "y6_pred=clf6.predict(X_text_test)\n",
    "f1_score(y_text_test, y6_pred)\n",
    "y6_tpred=clf6.predict(X_text_train)\n",
    "f1_score(y_text_train, y6_tpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STACKING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state =1,test_size = 0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(X_vectors,y_text, random_state =1,test_size = 0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForestClassifier()',\n",
       " 'KNeighborsClassifier()',\n",
       " 'MLPClassifier()',\n",
       " 'BernoulliNB()',\n",
       " 'ComplementNB()',\n",
       " 'TfIdf()']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_numericals= {'RandomForestClassifier()': RandomForestClassifier(bootstrap= False, max_depth= 12, max_features= 'auto', min_samples_leaf= 1, min_samples_split= 2, n_estimators= 100),\n",
    " 'KNeighborsClassifier()':KNeighborsClassifier(algorithm= 'auto', leaf_size=10, n_jobs= -1, n_neighbors= 5, p= 1, weights= 'distance'),\n",
    " 'MLPClassifier()': MLPClassifier(activation= 'tanh',alpha= 1e-05, early_stopping= True, hidden_layer_sizes= 250, learning_rate= 'invscaling', learning_rate_init= 0.01, max_iter= 3000, n_iter_no_change= 10, solver= 'lbfgs'),\n",
    " 'BernoulliNB()': BernoulliNB(alpha=0.1),\n",
    " 'ComplementNB()':ComplementNB(alpha=1.2) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers=[optimized_numericals['RandomForestClassifier()'].fit(X_train, y_train),\n",
    "            optimized_numericals['KNeighborsClassifier()'].fit(X_train, y_train),\n",
    "             optimized_numericals['MLPClassifier()'].fit(X_train, y_train),\n",
    "             optimized_numericals['BernoulliNB()'].fit(X_train, y_train),\n",
    "             optimized_numericals['ComplementNB()'].fit(X_train, y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf6= model_text.fit(X_text_train, y_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    4.9s remaining:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.31 (+/- 0.07) [RandomForestClassifier()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.25 (+/- 0.03) [KNeighborsClassifier()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   58.6s remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   59.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.27 (+/- 0.13) [MLPClassifier()]\n",
      "F1: 0.44 (+/- 0.09) [BernoulliNB()]\n",
      "F1: 0.27 (+/- 0.06) [ComplementNB()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.9min remaining:  2.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.45 (+/- 0.06) [StackingClassifier()]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.1min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "RANDOM_SEED = 1\n",
    "\n",
    "\n",
    "# Starting from v0.16.0, StackingCVRegressor supports\n",
    "# `random_state` to get deterministic result.\n",
    "sclf = StackingCVClassifier(classifiers=classifiers,\n",
    "                            meta_classifier=clf6,\n",
    "                            random_state=RANDOM_SEED)\n",
    "\n",
    "print('5-fold cross validation:\\n')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3,clf4, clf5, sclf], \n",
    "                      ['RandomForestClassifier()',\n",
    "                         'KNeighborsClassifier()',\n",
    "                         'MLPClassifier()',\n",
    "                         'BernoulliNB()',\n",
    "                         'ComplementNB()',\n",
    "                         'StackingClassifier()']):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, X, y, \n",
    "                                              cv=5, scoring='f1',\n",
    "                                             n_jobs=-1,verbose=1)\n",
    "    print(\"F1: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
