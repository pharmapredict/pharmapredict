{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%time is a cell magic, but the cell body is empty. Did you mean the line magic %time (single %)?\n"
     ]
    }
   ],
   "source": [
    "%%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change numerical features to %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load .csv\n",
    "\n",
    "df= pd.read_csv('../raw_data/wra_CT_PM_conclusions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numerical= df.select_dtypes(exclude='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Authorisation status</th>\n",
       "      <th>Orphan medicine</th>\n",
       "      <th>n_trials</th>\n",
       "      <th>status_not_yet_recruiting</th>\n",
       "      <th>status_recruiting</th>\n",
       "      <th>status_enrolling_by_invitation</th>\n",
       "      <th>status_active_not_recruiting</th>\n",
       "      <th>status_suspended</th>\n",
       "      <th>status_terminated</th>\n",
       "      <th>...</th>\n",
       "      <th>org_nih</th>\n",
       "      <th>org_other</th>\n",
       "      <th>org_other_gov</th>\n",
       "      <th>phase_early_1</th>\n",
       "      <th>phase_not_applicable</th>\n",
       "      <th>phase_1</th>\n",
       "      <th>phase_2</th>\n",
       "      <th>phase_3</th>\n",
       "      <th>phase_4</th>\n",
       "      <th>pm_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>65</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Authorisation status  Orphan medicine  n_trials  \\\n",
       "0           0                     0                0        54   \n",
       "1           1                     0                1        12   \n",
       "2           2                     0                0        20   \n",
       "3           3                     0                0       111   \n",
       "4           4                     0                0        20   \n",
       "\n",
       "   status_not_yet_recruiting  status_recruiting  \\\n",
       "0                          0                  2   \n",
       "1                          0                  2   \n",
       "2                          0                  0   \n",
       "3                          3                  8   \n",
       "4                          0                  0   \n",
       "\n",
       "   status_enrolling_by_invitation  status_active_not_recruiting  \\\n",
       "0                               0                             1   \n",
       "1                               0                             1   \n",
       "2                               0                             0   \n",
       "3                               0                             7   \n",
       "4                               0                             0   \n",
       "\n",
       "   status_suspended  status_terminated  ...  org_nih  org_other  \\\n",
       "0                 0                  3  ...        0         12   \n",
       "1                 0                  0  ...        0          2   \n",
       "2                 0                  0  ...        0          3   \n",
       "3                 0                 12  ...       13         53   \n",
       "4                 0                  0  ...        0          3   \n",
       "\n",
       "   org_other_gov  phase_early_1  phase_not_applicable  phase_1  phase_2  \\\n",
       "0              2              0                     2        1        2   \n",
       "1              0              0                     0        1        4   \n",
       "2              0              0                     2        0        0   \n",
       "3              4              1                     0       34       65   \n",
       "4              0              0                     2        0        0   \n",
       "\n",
       "   phase_3  phase_4  pm_results  \n",
       "0       17       30          44  \n",
       "1        3        0          11  \n",
       "2        5       12          36  \n",
       "3       21        0         523  \n",
       "4        5       12          36  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numerical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df_numerical.drop(labels= 'Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Authorisation status', 'Orphan medicine', 'n_trials',\n",
       "       'status_not_yet_recruiting', 'status_recruiting',\n",
       "       'status_enrolling_by_invitation', 'status_active_not_recruiting',\n",
       "       'status_suspended', 'status_terminated', 'status_completed',\n",
       "       'status_withdrawn', 'status_unknown', 'org_fed', 'org_indiv',\n",
       "       'org_industry', 'org_network', 'org_nih', 'org_other', 'org_other_gov',\n",
       "       'phase_early_1', 'phase_not_applicable', 'phase_1', 'phase_2',\n",
       "       'phase_3', 'phase_4', 'pm_results'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numerical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_list= df_numerical.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['status_not_yet_recruiting', 'status_recruiting',\n",
       "       'status_enrolling_by_invitation', 'status_active_not_recruiting',\n",
       "       'status_suspended', 'status_terminated', 'status_completed',\n",
       "       'status_withdrawn', 'status_unknown', 'org_fed', 'org_indiv',\n",
       "       'org_industry', 'org_network', 'org_nih', 'org_other', 'org_other_gov',\n",
       "       'phase_early_1', 'phase_not_applicable', 'phase_1', 'phase_2',\n",
       "       'phase_3', 'phase_4', 'pm_results'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for column in percent_list:\n",
    "    df_numerical[column]=((df_numerical[column]*100)/df_numerical['n_trials']).replace([np.inf, -np.inf, np.nan], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_columns(df,column_list,column_total):\n",
    "    for column in column_list:\n",
    "        df[column]=((df[column]*100)/df[column_total]).replace([np.inf, -np.inf, np.nan], 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned=df_numerical[df_numerical['n_trials']< 3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df_cleaned.drop(labels='Authorisation status', axis=1)\n",
    "y=df_cleaned['Authorisation status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "X_new = SelectKBest(chi2, k=10).fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1359, 10)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler().fit(X_new)\n",
    "X_new= scaler.transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_new,y, test_size= 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8455882352941176"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn= KNeighborsClassifier()\n",
    "knn.fit(X_train,y_train)\n",
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "cv_results= cross_validate(knn, X_train, y_train, cv=5,\n",
    "                          scoring=['accuracy','f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1: {0.40358612935974564}\n",
      "Test accuracy: {0.8638523654504713}\n"
     ]
    }
   ],
   "source": [
    "#print('Train f1:', cv_results['train_f1_macro'].mean())\n",
    "#print('Train accuracy:', {cv_results['train_accuracy'].mean()})\n",
    "\n",
    "\n",
    "print(f'Test f1:',{cv_results['test_f1'].mean()})\n",
    "print(f'Test accuracy:', {cv_results['test_accuracy'].mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numerical.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Mierda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df_numerical.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "group = df.groupby(['Authorisation status','Generic']).size().unstack(level=1)\n",
    "group.plot(kind = 'barh',stacked = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "group = df.groupby(['Authorisation status','Orphan medicine']).size().unstack(level=1)\n",
    "group.plot(kind = 'barh',stacked = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(data = df, x = 'Authorisation status',y = 'Orphan medicine', kind = 'box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for column in percent_list:\n",
    "    sns.catplot(data = df_cleaned, x = 'Authorisation status',y = column, kind = 'box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(percent_list)\n",
    "top_list= ['phase_4', 'Orphan medicine', \n",
    "           'org_indiv', 'n_trials', \n",
    "           'status_terminated', 'phase_2', \n",
    "           'phase_3', 'status_not_yet_recruiting', \n",
    "           'org_fed', 'org_nih','Authorisation status']\n",
    "top_list_2= ['org_industry',  'n_trials',  'phase_4',\n",
    "             'org_other', 'status_completed', 'status_recruiting',\n",
    "             'phase_3',  'pm_results', 'status_not_yet_recruiting',\n",
    "             'phase_2','Authorisation status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_secondmodel= df_cleaned[top_list_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2= df_secondmodel.drop(labels='Authorisation status', axis=1)\n",
    "y2=df_secondmodel['Authorisation status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test= train_test_split(X2,y2, test_size= 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler().fit(X2_train)\n",
    "X2_train= scaler.transform(X2_train)\n",
    "X2_test= scaler.transform(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn= KNeighborsClassifier()\n",
    "knn.fit(X2_train,y2_train)\n",
    "y2_pred= knn.predict(X2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       939\n",
      "           1       0.56      0.43      0.49       148\n",
      "\n",
      "    accuracy                           0.88      1087\n",
      "   macro avg       0.74      0.69      0.71      1087\n",
      "weighted avg       0.87      0.88      0.87      1087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y2_train, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With several models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard models\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model_list= [SVC(), RandomForestClassifier(),\n",
    "              BernoulliNB(), ComplementNB(), \n",
    "              KNeighborsClassifier(), MLPClassifier(max_iter=1000),\n",
    "              SGDClassifier()]\n",
    "model_scoring_test= {}\n",
    "model_scoring_train={}\n",
    "\n",
    "for model in model_list:\n",
    "    model.fit(X2_train,y2_train)\n",
    "    y2_pred_test= model.predict(X2_test)\n",
    "    y2_pred_train= model.predict(X2_train)\n",
    "    \n",
    "    model_scoring_test[str(model)]= f1_score(y2_test, y2_pred_test)\n",
    "    model_scoring_train[str(model)]= f1_score(y2_train, y2_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------SCORE ON TRAIN---------------\n",
      "{'SVC()': 0.08974358974358974, 'RandomForestClassifier()': 0.8787878787878788, 'BernoulliNB()': 0.46496815286624205, 'ComplementNB()': 0.3080082135523614, 'KNeighborsClassifier()': 0.48854961832061067, 'MLPClassifier(max_iter=1000)': 0.3804878048780488, 'SGDClassifier()': 0.013333333333333332}\n",
      "--------SCORE ON TEST---------------\n",
      "{'SVC()': 0.0, 'RandomForestClassifier()': 0.19999999999999996, 'BernoulliNB()': 0.3658536585365854, 'ComplementNB()': 0.2882882882882883, 'KNeighborsClassifier()': 0.28169014084507044, 'MLPClassifier(max_iter=1000)': 0.09090909090909091, 'SGDClassifier()': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print('--------SCORE ON TRAIN---------------')\n",
    "print(model_scoring_train)\n",
    "print('--------SCORE ON TEST---------------')\n",
    "print(model_scoring_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_shortlist= [RandomForestClassifier(),KNeighborsClassifier(), MLPClassifier(), BernoulliNB(),ComplementNB()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [50, 100, 200, 300, 400],\n",
    "              'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [1 , 5 , 10, 12],\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False],\n",
    "                'class_weight': ['balanced'] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= GridSearchCV(RandomForestClassifier(), param_grid, scoring='f1',\n",
    "                cv= 5, n_jobs=-1, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   55.7s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3600 out of 3600 | elapsed:  9.2min finished\n"
     ]
    }
   ],
   "source": [
    "clf = clf.fit(X2_train, y2_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "RandomForestClassifier(bootstrap=False, max_depth=12)\n",
      "Best params:\n",
      "{'bootstrap': False, 'max_depth': 12, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best score found by grid search:\n",
      "0.3535139576141116\n"
     ]
    }
   ],
   "source": [
    "print(\"Best estimator found by grid search:\")\n",
    "print(clf.best_estimator_)\n",
    "print(\"Best params:\")\n",
    "print(clf.best_params_)\n",
    "print(\"Best score found by grid search:\")\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a74ad04ea648>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best= clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24000000000000002"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best.fit(X2_train, y2_train)\n",
    "y_rf_pred= rf_best.predict(X2_test)\n",
    "\n",
    "f1_score(y2_test, y_rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       233\n",
      "           1       0.55      0.15      0.24        39\n",
      "\n",
      "    accuracy                           0.86       272\n",
      "   macro avg       0.71      0.57      0.58       272\n",
      "weighted avg       0.83      0.86      0.83       272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y2_test, y_rf_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(confusion_matrix(y2_test, y_rf_pred),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid2 = {'n_neighbors': [1,2,3,4, 5, 6, 7],\n",
    "               'weights': ['uniform', 'distance'],\n",
    "               'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "               'leaf_size': [5,10,20],\n",
    "               'p': [1, 2],\n",
    "               'n_jobs': [-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2= GridSearchCV(KNeighborsClassifier(), param_grid2, scoring='f1',\n",
    "                cv= 5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 336 candidates, totalling 1680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1680 out of 1680 | elapsed:   30.4s finished\n"
     ]
    }
   ],
   "source": [
    "clf2 = clf2.fit(X2_train, y2_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(leaf_size=10, n_jobs=-1, p=1, weights='distance')"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "{'algorithm': 'auto', 'leaf_size': 10, 'n_jobs': -1, 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
      "Best score found by grid search:\n",
      "0.4565932517095307\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\")\n",
    "print(clf2.best_params_)\n",
    "print(\"Best score found by grid search:\")\n",
    "print(clf2.best_score_)\n",
    "kn_best= clf2.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_best.fit(X2_train, y2_train)\n",
    "y_kn_pred= kn_best.predict(X2_test)\n",
    "\n",
    "f1_score(y2_test, y_kn_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90       233\n",
      "           1       0.40      0.46      0.43        39\n",
      "\n",
      "    accuracy                           0.82       272\n",
      "   macro avg       0.65      0.67      0.66       272\n",
      "weighted avg       0.83      0.82      0.83       272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y2_test, y_kn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(confusion_matrix(y2_test, y_kn_pred),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Implement the third grid\n",
    "param_grid3 = {'hidden_layer_sizes': [200,250],\n",
    "               'activation': ['logistic', 'tanh', 'relu'],\n",
    "               'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "               'alpha': [0.0001, 0.00001],\n",
    "               'learning_rate_init':[0.01 , 0.05],\n",
    "               'learning_rate': ['invscaling', 'adaptive'],\n",
    "               'n_iter_no_change': [10],\n",
    "               'max_iter': [3000],\n",
    "               'early_stopping': [True]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3= GridSearchCV(MLPClassifier(), param_grid3, scoring='f1',\n",
    "                cv= 5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 19.3min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed: 29.5min finished\n",
      "c:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "clf3 = clf3.fit(X2_train, y2_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "{'activation': 'tanh', 'alpha': 1e-05, 'early_stopping': True, 'hidden_layer_sizes': 250, 'learning_rate': 'invscaling', 'learning_rate_init': 0.01, 'max_iter': 3000, 'n_iter_no_change': 10, 'solver': 'lbfgs'}\n",
      "Best score found by grid search:\n",
      "0.37621625204365694\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\")\n",
    "print(clf3.best_params_)\n",
    "print(\"Best score found by grid search:\")\n",
    "print(clf3.best_score_)\n",
    "mlp_best= clf3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.276923076923077"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_best.fit(X2_train, y2_train)\n",
    "y_mlp_pred= mlp_best.predict(X2_test)\n",
    "\n",
    "f1_score(y2_test, y_mlp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90       233\n",
      "           1       0.35      0.23      0.28        39\n",
      "\n",
      "    accuracy                           0.83       272\n",
      "   macro avg       0.61      0.58      0.59       272\n",
      "weighted avg       0.80      0.83      0.81       272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y2_test, y_mlp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y2_test, y_mlp_pred),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid4 = {'alpha': [0.1, 0.01 , 0.5, 0.7, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4= GridSearchCV(BernoulliNB(), param_grid4, scoring= 'f1',\n",
    "                cv= 5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "clf4 = clf4.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "{'alpha': 0.1}\n",
      "Best score found by grid search:\n",
      "0.46526256805799876\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\")\n",
    "print(clf4.best_params_)\n",
    "print(\"Best score found by grid search:\")\n",
    "print(clf4.best_score_)\n",
    "ber_best= clf4.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3658536585365854"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ber_best.fit(X2_train, y2_train)\n",
    "y_ber_pred= ber_best.predict(X2_test)\n",
    "\n",
    "f1_score(y2_test, y_ber_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       233\n",
      "           1       0.35      0.38      0.37        39\n",
      "\n",
      "    accuracy                           0.81       272\n",
      "   macro avg       0.62      0.63      0.63       272\n",
      "weighted avg       0.82      0.81      0.81       272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y2_test, y_ber_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y2_test, y_ber_pred),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search ComplementNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid5 = {'alpha': [1, 1.2,1.5,1.7,2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf5= GridSearchCV(ComplementNB(), param_grid5, scoring='f1',\n",
    "                cv= 5, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "clf5 = clf5.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComplementNB(alpha=1.2)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "{'alpha': 1.2}\n",
      "Best score found by grid search:\n",
      "0.2998219553569215\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\")\n",
    "print(clf5.best_params_)\n",
    "print(\"Best score found by grid search:\")\n",
    "print(clf5.best_score_)\n",
    "comp_best= clf5.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2882882882882883"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_best.fit(X2_train, y2_train)\n",
    "y_comp_pred= comp_best.predict(X2_test)\n",
    "\n",
    "f1_score(y2_test, y_comp_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.76      0.82       233\n",
      "           1       0.22      0.41      0.29        39\n",
      "\n",
      "    accuracy                           0.71       272\n",
      "   macro avg       0.55      0.58      0.55       272\n",
      "weighted avg       0.79      0.71      0.74       272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y2_test, y_comp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD4CAYAAADSIzzWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWk0lEQVR4nO3de5xVVd3H8c9X8P4gFylAsEdI1NS0lAhTS9NSvIGvegw0pcKmvDxPpqlIJi8lkyyyTLMXIYqXMLxCpqGhqXkBQcFrGqHIEHIREBQTZ87v+WO2dESYc+bMMIuz+b59rRfnrL1n7TVFv37+9tp7KSIwM7PWt0XqCZiZba4cgM3MEnEANjNLxAHYzCwRB2Azs0TabuwLvLd0rpdZ2IfU9Dk39RRsE3Tdq7eruWM0JeZs2blXs6/XHM6AzcwS2egZsJlZqyrUp55B2RyAzSxf6utSz6BsDsBmlisRhdRTKJsDsJnlS8EB2MwsDWfAZmaJ+CacmVkizoDNzNIIr4IwM0vEN+HMzBJxCcLMLBHfhDMzS8QZsJlZIr4JZ2aWiG/CmZmlEeEasJlZGq4Bm5kl4hKEmVkiVZQBe0siM8uX+vfKbyVIGidpsaTn1un/X0l/l/S8pMuL+i+QNEfSS5KOKDW+M2Azy5eWLUFcD1wF3PB+h6RDgQHAvhHxrqSPZv17AoOAvYCdgL9I2i0auSvoDNjM8iUK5bdSQ0U8DCxbp/s0YFREvJudszjrHwDcEhHvRsQrwBygb2PjOwCbWb4UCmU3STWSZhS1mjKusBtwsKRpkh6S9Jmsvzswv+i82qxvg1yCMLN8aUIJIiLGAGOaeIW2QCegH/AZYKKkXk0cY+1AZma5EWXcXGumWuCOiAhguqQC0BlYAOxcdF6PrG+DXIIws3xpwRrwBtwFHAogaTdgK2ApMBkYJGlrST2B3sD0xgZyBmxm+dKCqyAkTQAOATpLqgVGAOOAcdnStDXAkCwbfl7SROAFoA44o7EVEOAAbGZ504IPYkTE4A0c+voGzr8UuLTc8R2AzSxf/CiymVkiVfQosgOwmeVLnV/IbmaWhjNgM7NEXAM2M0vEGbCZWSLOgM3MEnEGbGaWiFdBmJklEpF6BmVzADazfHEN2MwsEQdgM7NEfBPOzCyR+kbfALlJcQA2s3xxCcLMLBEHYDOzRFwDNjNLIwrVsw7Ym3KaWb4UCuW3EiSNk7Q42/9t3WPnSApJnbPvknSlpDmSnpG0X6nxHYDNLF/q68tvpV0PHLlup6SdgS8DrxV196dhJ+TeQA1wTanBHYDNLF9aMAOOiIeBZes5dAVwHlBc7xgA3BANngA6SOrW2PgOwGaWL00IwJJqJM0oajWlhpc0AFgQEbPXOdQdmF/0vTbr2yDfhGvEhT/5BQ8/Op1OHTtw102//dDxVW+9zbBLLmfhoiXU19XzjRO/wvFHf7lZ13xz5SrO+dFl/Ov1RezUtQujR15A+x3acfeUB7j25lshYLvttuVHPziTPXr3ata1LI2f/e0a/v3WOxQKBerr6rnkuPMBOGxIfw47pT+F+gKzH5jJraNuTDzTKtWEl/FExBhgTLnnS9oOGE5D+aHZHIAbMfCoL3HiV45j+Mifr/f4hNv/yMd3+RhXX34xy5av4JjB3+aYLx/KlltuWXLs6U89w6R77ufSC8/5QP/YGyfSr8+nOPXkExh740SuvWkiZ58+lO47deX6qy6n/Q7teOTxJ7n48iuZ8LtftsSvaQn8dPAI3lq+au33PQ7Ym09/qS8X9T+bujV1tNtxh4Szq3Ibdx3wx4GewGxJAD2ApyT1BRYAOxed2yPr26CSJQhJe0g6P7u7d2X2+RMVT7+K9PnUJ2m/Q7sNHpfE26vfISJY/c6/ab9DO9q0aQPAuJtv42tD/4/jTzmNq8aWn8k8+MjjDOh/OAAD+h/OAw8/DsCnP7nn2rnss9ceLFq8tNJfyzZBh550BPdccyd1axreZbvqjZWJZ1TFClF+a6KIeDYiPhoRu0TELjSUGfaLiNeBycAp2WqIfsCbEbGwsfEaDcCSzgduAQRMz5qACZKGNXn2OXPiV45l7qvzOXTASRx/ymkMO+u7bLHFFjw6bSav1S7glrG/4vbrr+aFl+YwY9azZY35xvIVfKRzJwA679iRN5av+NA5d9w9hYP69WnJX8VaUUTwgxsvYsQfL+cLg78EQNde3dit7ye48K7LOP8Pl9Bzn48nnmUVa8FVEJImAI8Du0uqlTS0kdPvAeYCc4DfAaeXGr9UCWIosFdEvLfOpH4BPA+M2sCka2hYhsFvRv+YU08ZXGoeVenR6TPZo3cvxv16FPMXLOTbZw1n/3334rEnn+Kx6U/x1W+cCcDqd95h3vx/0edTn2Twt89izZr3WP3OO7y5chVfGXIGAGef/i0O/Oz+HxhfEtm/5qw1feZs7rj7Pm68Zv1lEdv0/eSrF7Ji0TLa7bgDP7hpBAv/uYAt2rRh+/b/xY8HXkDPfXfltKvP4byDS/7v19YjWrAEERGNBq8sC37/cwBnNGX8UgG4AOwEzFunv1t2bEOTWlvYfm/p3Op5LKWJ7vzT/Zz69ROQxMd67ET3bl15ZV4tBJx68tc4YeBRH/qZ9+u2G6oB79ixA0uWLuMjnTuxZOkyOnVov/bYS3Ne4aJRv+S3o0fSob1rhNVqxaKGVU2r3ljJU1Om0WvfXVn++hvMnDINgFdmzyEKQbtOO7BqmUsRTZajJ+HOAqZKulfSmKz9GZgKfG+jz24T163LR3hi5iwAli5bzquv1dJjp658ru9+3Pmn+1i9+h0AFi1Zut5SwvocclA/Jt37FwAm3fsXDj34AAAWvr6Ys4aP5LKLzmWXj/Vo8d/FWsdW227NNttvs/bz3gfvS+3Lr/HUfdPZo9/eAHTp2Y22W7Z18K1UFMpviTWaAUfEnyXtBvTlP+vZFgBPRkT1vHSzQueOGMWTTz/DihUrOWzg1zl96MnUZRv+fe34o/nuN07kh5eO5viTTyMi+P7p36Jjh/Yc+Nn9mTtvPid952wAttt2Gy676Fx27Nih5DVPPfkEzvnRT7jj7ins1PWjjB45HIBrrvs9b65cxY9/fjUAbdq0YeK4KzfOL24bTfvOHThzzHlAw3+HT0x6hOcemkWbLdsy9PLTGTnlCurfq2PsOb9OPNMqVkUZsGIjb2CX5xKEVa6mz7mpp2CboOtevV2lz2rc2xcNKjvmbH/JLc2+XnN4HbCZ5csmUFoolwOwmeVLFZUgHIDNLFdachnaxuYAbGb54gzYzCwRB2Azs0S8Lb2ZWRrVtCecA7CZ5YsDsJlZIl4FYWaWiDNgM7NEHIDNzNKIepcgzMzScAZsZpZGNS1DK7kpp5lZVWnBTTkljZO0WNJzRX0/k/R3Sc9IulNSh6JjF0iaI+klSUeUGt8B2MzypdCEVtr1wJHr9N0P7B0R+wAvAxcASNoTGATslf3MbyS1aWxwB2Azy5WoK5TdSo4V8TCwbJ2++yKiLvv6BPD+HmEDgFsi4t2IeIWG3ZH7Nja+A7CZ5UsTMmBJNZJmFLWaJl7tW8C92efuwPyiY7X8Zyu39fJNODPLlabchCvewb2pJP0QqANuruTnwQHYzPKmFZYBS/oGcAxwWPxnY80FwM5Fp/XI+jbIJQgzy5UoRNmtEpKOBM4DjouI1UWHJgODJG0tqSfQG5je2FjOgM0sX1owA5Y0ATgE6CypFhhBw6qHrYH7JQE8ERHfjYjnJU0EXqChNHFGRDT6cmIHYDPLlbXrE1pirIjB6+m+tpHzLwUuLXd8B2Azy5Uq2pXeAdjMcsYB2MwsDWfAZmaJOACbmSUS9Uo9hbI5AJtZrjgDNjNLJArOgM3MknAGbGaWSIQzYDOzJJwBm5klUvAqCDOzNHwTzswsEQdgM7NEonp2pXcANrN8cQZsZpaIl6GZmSVS71UQZmZpVFMG7E05zSxXoqCyWymSxklaLOm5or5Oku6X9I/sz45ZvyRdKWmOpGck7VdqfAdgM8uViPJbGa4HjlynbxgwNSJ6A1Oz7wD9adgJuTdQA1xTanAHYDPLlZbMgCPiYWDZOt0DgPHZ5/HAwKL+G6LBE0AHSd0aG981YDPLlfpC+XmlpBoastX3jYmIMSV+rEtELMw+vw50yT53B+YXnVeb9S1kAxyAzSxXmvIgRhZsSwXcxn4+JFX86IcDsJnlSmHjr4JYJKlbRCzMSgyLs/4FwM5F5/XI+jbINWAzy5UIld0qNBkYkn0eAkwq6j8lWw3RD3izqFSxXs6AzSxXWvJdEJImAIcAnSXVAiOAUcBESUOBecAJ2en3AEcBc4DVwDdLjh8b+c0Vndr1rqJXY1hrWfnu6tRTsE1Q3ZoFza4fzOgxsOyY06f2rqRPbTgDNrNcacoqiNQcgM0sV6rpX7kdgM0sV1phFUSLcQA2s1ypppfxOACbWa5U0abIDsBmli+BM2AzsyTqXIIwM0vDGbCZWSKuAZuZJeIM2MwsEWfAZmaJ1DsDNjNLo4ydhjYZDsBmlisFZ8BmZmn4ZTxmZon4JpyZWSIFuQRhZpZEfeoJNEH1vDrezKwMBZXfSpH0fUnPS3pO0gRJ20jqKWmapDmS/iBpq0rn6gBsZrlSQGW3xkjqDvwf0Cci9gbaAIOAnwJXRMSuwHJgaKVzdQA2s1yJJrQytAW2ldQW2A5YCHwRuC07Ph4YWOlcHYDNLFeaUoKQVCNpRlGreX+ciFgA/Bx4jYbA+yYwE1gREXXZabVA90rn6ptwZpYrTVmGFhFjgDHrOyapIzAA6AmsAG4Fjmzu/Io5AJtZrtS33Cq0w4FXImIJgKQ7gAOBDpLaZllwD2BBpRdwCcLMcqXQhFbCa0A/SdtJEnAY8ALwIPDV7JwhwKRK5+oAbGa50lIBOCKm0XCz7SngWRri5RjgfOBsSXOAHYFrK52rSxBmlistuSVcRIwARqzTPRfo2xLjOwCbWa74XRBmZolU06PIDsBmlit+IbuZWSIuQZiZJeIAbGaWiHfEMDNLxDVgM7NEvArCzCyRQhUVIRyAzSxXfBPOzCyR6sl/HYDNLGecAZuZJVKn6smBHYDNLFeqJ/w6AJtZzrgEYWaWiJehmZklUj3h1wHYzHKmmkoQ3hPOzHKlnii7lSKpg6TbJP1d0ouSDpDUSdL9kv6R/dmx0rk6AJtZrrTgrsgAvwL+HBF7APsCLwLDgKkR0RuYmn2viAOwmeVKNOGfxkhqD3yebNfjiFgTESuAAcD47LTxwMBK5+oAbGa50pQMWFKNpBlFraZoqJ7AEuA6SU9LGitpe6BLRCzMznkd6FLpXB2AN5Lu3bsy6U838viT9/LY9Hv4zmlDABh+4Vk88vgfeejRydx+13V07frRxDO11vS7MaP5V+1sZj099QP9Z5z+TZ579iFmz3qAUZf9MNHs8qFAlN0iYkxE9ClqY4qGagvsB1wTEZ8G3madckNEBM1YeOEAvJHU1dXzo+GXccBn+vPlL/4PQ2tOYvfdd+XXvxrLwQccyxcOPI4pf36Qc4edmXqq1opuuGEiRx9z0gf6DvnC5zju2CPYb/8vse+nvsjoX/w20ezyIZrQSqgFaiNiWvb9NhoC8iJJ3QCyPxdXOlcH4I1k0aIlPDP7BQDeeuttXn7pn3TbqQurVr219pzttt+Whv8Dtc3FI3+bxrLlKz7Q953vnMLlP7uaNWvWALBkyRsJZpYfdUTZrTER8TowX9LuWddhwAvAZGBI1jcEmFTpXL0OuBXs/LHu7LPPnsycMRuAH170fQYNPp6VK1dx3NEnJ56dpda7dy8OOqgvIy85j3//+13OO38kM2bOTj2tqlXq5loT/S9ws6StgLnAN2lIXCdKGgrMA06odPCKM2BJ32zk2NrC9rvvvVnpJXJh++23Y/xNVzF82KVrs99LL7mCT37i89w6cTLfrvl64hlaam3btqFjxw587qBjOX/Yj5nwe5cgmqMll6FFxKysNrxPRAyMiOUR8UZEHBYRvSPi8IhYVulcm1OCuHhDB4oL21tv2b4Zl6hubdu2ZfxNV3HbxMncPfm+Dx2/9Q+TOXbAEQlmZpuSBbULueuuewF4csYsCoUCnTt3Sjyr6tVSy9BaQ6MlCEnPbOgQzVh6sbm48uqf8PJL/+Q3V123tq/Xx/+buf+cB8BRRx/OP16em2p6tomYNHkKhxzyOf760GP07t2LrbbaiqVLK06qNnvV9ChyqRpwF+AIYPk6/QIe2ygzyonPHrA/g048nuef+zsPPToZgJEXj+bkU/6HXXv3pFAoMH/+vzjnexclnqm1pptuvJovfP4AOnfuxKtzZ3DxJT/nuutvYezvRjPr6amsWfMe3xp6VuppVrX6Krqxrcbuwku6FrguIv62nmO/j4gTS12gU7ve1fOfhrWale+uTj0F2wTVrVmg5o5x4n8fX3bM+f28O5t9veZoNAOOiKGNHCsZfM3MWtumUNstl5ehmVmu5KkGbGZWVbwjhplZIi5BmJklUk2rIByAzSxXXIIwM0vEN+HMzBJxDdjMLBGXIMzMEqmmd2w7AJtZrpSz3fymwgHYzHLFJQgzs0RcgjAzS6SaMmBvymlmudLSO2JIaiPpaUl3Z997SpomaY6kP2T7xVXEAdjMcqU+ouxWpu8BLxZ9/ylwRUTsSsNmFRt8bW8pDsBmlisFouxWiqQewNHA2Oy7gC8Ct2WnjAcGVjpXB2Azy5WmBODiHdyzVrPOcL8EzuM/TzjvCKyIiLrsey3QvdK5+iacmeVKU1ZBRMQYYMz6jkk6BlgcETMlHdIik1uHA7CZ5UoLroI4EDhO0lHANsAOwK+ADpLaZllwD2BBpRdwCcLMcqWlVkFExAUR0SMidgEGAQ9ExEnAg8BXs9OGAJMqnasDsJnlSn0Uym4VOh84W9IcGmrC11Y6kEsQZpYrG+NJuIj4K/DX7PNcoG9LjOsAbGa5Uk1PwjkAm1mu+IXsZmaJFPwyHjOzNJwBm5kl0ozVDa3OAdjMcsUlCDOzRFyCMDNLxBmwmVkizoDNzBKpj/rUUyibA7CZ5Yo35TQzS8SPIpuZJeIM2MwsEa+CMDNLxKsgzMwS8aPIZmaJuAZsZpZINdWAvSecmeVKRJTdGiNpZ0kPSnpB0vOSvpf1d5J0v6R/ZH92rHSuDsBmlisFouxWQh1wTkTsCfQDzpC0JzAMmBoRvYGp2feKOACbWa60VAYcEQsj4qns8yrgRaA7MAAYn502HhhY6VxdAzazXGnKKghJNUBNUdeYiBiznvN2AT4NTAO6RMTC7NDrQJdK5+oAbGa50pSbcFmw/VDALSbpv4DbgbMiYqWk4p8PSRXf9XMANrNcacllaJK2pCH43hwRd2TdiyR1i4iFkroBiysd3zVgM8uVaMI/jVFDqnst8GJE/KLo0GRgSPZ5CDCp0rk6AzazXGnBDPhA4GTgWUmzsr7hwChgoqShwDzghEov4ABsZrnSUg9iRMTfAG3g8GEtcQ1V02N71U5SzfrusNrmzX8vNl+uAbeumtKn2GbIfy82Uw7AZmaJOACbmSXiANy6XOez9fHfi82Ub8KZmSXiDNjMLBEHYDOzRByAW4mkIyW9JGmOpIrfH2r5IWmcpMWSnks9F0vDAbgVSGoDXA30B/YEBmcvdrbN2/XAkaknYek4ALeOvsCciJgbEWuAW2h4qbNtxiLiYWBZ6nlYOg7AraM7ML/oe23WZ2abMQdgM7NEHIBbxwJg56LvPbI+M9uMOQC3jieB3pJ6StoKGETDS53NbDPmANwKIqIOOBOYQsPOqhMj4vm0s7LUJE0AHgd2l1SbveDbNiN+FNnMLBFnwGZmiTgAm5kl4gBsZpaIA7CZWSIOwGZmiTgAm5kl4gBsZpbI/wPdwJUBdKVsJwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(y2_test, y_comp_pred),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUMMARY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (2,3):\n",
    "    f'cl{i}.best_estimator_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in model_shortlist:\n",
    "    model_summary[str(model)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary['RandomForestClassifier()']= 0.24000000000000002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary['KNeighborsClassifier()']= 0.42857142857142855  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary['MLPClassifier()']= 0.34375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary['BernoulliNB()']= 0.3658536585365854"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_summary['ComplementNB()']= 0.2882882882882883\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RandomForestClassifier()': 0.24000000000000002,\n",
       " 'KNeighborsClassifier()': 0.42857142857142855,\n",
       " 'MLPClassifier()': 0.34375,\n",
       " 'BernoulliNB()': 0.3658536585365854,\n",
       " 'ComplementNB()': 0.2882882882882883}"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_columns(df,column_list,column_total):\n",
    "    for column in column_list:\n",
    "        df[column]=((df[column]*100)/df[column_total]).replace([np.inf, -np.inf, np.nan], 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_dumb= percentage_columns(df_numerical, percent_columns, 'n_trials')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orphan medicine</th>\n",
       "      <th>n_trials</th>\n",
       "      <th>status_not_yet_recruiting</th>\n",
       "      <th>status_recruiting</th>\n",
       "      <th>status_enrolling_by_invitation</th>\n",
       "      <th>status_active_not_recruiting</th>\n",
       "      <th>status_suspended</th>\n",
       "      <th>status_terminated</th>\n",
       "      <th>status_completed</th>\n",
       "      <th>status_withdrawn</th>\n",
       "      <th>...</th>\n",
       "      <th>org_nih</th>\n",
       "      <th>org_other</th>\n",
       "      <th>org_other_gov</th>\n",
       "      <th>phase_early_1</th>\n",
       "      <th>phase_not_applicable</th>\n",
       "      <th>phase_1</th>\n",
       "      <th>phase_2</th>\n",
       "      <th>phase_3</th>\n",
       "      <th>phase_4</th>\n",
       "      <th>pm_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.858711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.429355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.288066</td>\n",
       "      <td>147.462277</td>\n",
       "      <td>10.288066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.152263</td>\n",
       "      <td>6.858711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.858711</td>\n",
       "      <td>3.429355</td>\n",
       "      <td>6.858711</td>\n",
       "      <td>58.299040</td>\n",
       "      <td>102.880658</td>\n",
       "      <td>150.891632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.444444</td>\n",
       "      <td>277.777778</td>\n",
       "      <td>208.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>763.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>2.434867</td>\n",
       "      <td>6.492979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.681357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.739469</td>\n",
       "      <td>51.943836</td>\n",
       "      <td>2.434867</td>\n",
       "      <td>...</td>\n",
       "      <td>10.551092</td>\n",
       "      <td>43.015989</td>\n",
       "      <td>3.246490</td>\n",
       "      <td>0.811622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.595163</td>\n",
       "      <td>52.755458</td>\n",
       "      <td>17.044071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>424.478533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>46.296296</td>\n",
       "      <td>84.876543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.432099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>108.024691</td>\n",
       "      <td>7.716049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>108.024691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.716049</td>\n",
       "      <td>38.580247</td>\n",
       "      <td>15.432099</td>\n",
       "      <td>84.876543</td>\n",
       "      <td>92.592593</td>\n",
       "      <td>30.864198</td>\n",
       "      <td>408.950617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>909.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>826.446281</td>\n",
       "      <td>82.644628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>909.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>826.446281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0.573921</td>\n",
       "      <td>5.739210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.739210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.295684</td>\n",
       "      <td>51.652893</td>\n",
       "      <td>2.869605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573921</td>\n",
       "      <td>39.600551</td>\n",
       "      <td>1.147842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.460973</td>\n",
       "      <td>6.313131</td>\n",
       "      <td>19.513315</td>\n",
       "      <td>15.495868</td>\n",
       "      <td>19.513315</td>\n",
       "      <td>808.080808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2.687450</td>\n",
       "      <td>2.687450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.374899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.437248</td>\n",
       "      <td>118.247783</td>\n",
       "      <td>5.374899</td>\n",
       "      <td>...</td>\n",
       "      <td>2.687450</td>\n",
       "      <td>48.374093</td>\n",
       "      <td>2.687450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.499597</td>\n",
       "      <td>2.687450</td>\n",
       "      <td>29.561946</td>\n",
       "      <td>56.436442</td>\n",
       "      <td>45.686643</td>\n",
       "      <td>2112.335394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>618</td>\n",
       "      <td>0.288015</td>\n",
       "      <td>1.885192</td>\n",
       "      <td>0.052366</td>\n",
       "      <td>0.837863</td>\n",
       "      <td>0.026183</td>\n",
       "      <td>1.073512</td>\n",
       "      <td>10.001990</td>\n",
       "      <td>0.366565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130916</td>\n",
       "      <td>6.283973</td>\n",
       "      <td>0.130916</td>\n",
       "      <td>0.026183</td>\n",
       "      <td>0.942596</td>\n",
       "      <td>0.497481</td>\n",
       "      <td>1.806642</td>\n",
       "      <td>4.634430</td>\n",
       "      <td>3.220536</td>\n",
       "      <td>154.192981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.644628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.644628</td>\n",
       "      <td>661.157025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>82.644628</td>\n",
       "      <td>247.933884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>165.289256</td>\n",
       "      <td>578.512397</td>\n",
       "      <td>82.644628</td>\n",
       "      <td>165.289256</td>\n",
       "      <td>13801.652893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>816.326531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>204.081633</td>\n",
       "      <td>204.081633</td>\n",
       "      <td>1020.408163</td>\n",
       "      <td>204.081633</td>\n",
       "      <td>5918.367347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>2085</td>\n",
       "      <td>0.149521</td>\n",
       "      <td>0.687795</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.395655</td>\n",
       "      <td>0.011502</td>\n",
       "      <td>0.577380</td>\n",
       "      <td>2.272714</td>\n",
       "      <td>0.128818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259936</td>\n",
       "      <td>2.946707</td>\n",
       "      <td>0.055208</td>\n",
       "      <td>0.016102</td>\n",
       "      <td>0.170224</td>\n",
       "      <td>0.782108</td>\n",
       "      <td>2.866196</td>\n",
       "      <td>1.104153</td>\n",
       "      <td>0.105815</td>\n",
       "      <td>22.743244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0.573921</td>\n",
       "      <td>5.739210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.739210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.295684</td>\n",
       "      <td>51.652893</td>\n",
       "      <td>2.869605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573921</td>\n",
       "      <td>39.600551</td>\n",
       "      <td>1.147842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.460973</td>\n",
       "      <td>6.313131</td>\n",
       "      <td>19.513315</td>\n",
       "      <td>15.495868</td>\n",
       "      <td>19.513315</td>\n",
       "      <td>810.376492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>6.611570</td>\n",
       "      <td>39.669421</td>\n",
       "      <td>3.305785</td>\n",
       "      <td>33.057851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.528926</td>\n",
       "      <td>62.809917</td>\n",
       "      <td>9.917355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.231405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.305785</td>\n",
       "      <td>26.446281</td>\n",
       "      <td>109.090909</td>\n",
       "      <td>19.834711</td>\n",
       "      <td>16.528926</td>\n",
       "      <td>1712.396694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>262</td>\n",
       "      <td>1.311112</td>\n",
       "      <td>4.224696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.748150</td>\n",
       "      <td>0.145679</td>\n",
       "      <td>1.165433</td>\n",
       "      <td>25.348173</td>\n",
       "      <td>0.728396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145679</td>\n",
       "      <td>14.276557</td>\n",
       "      <td>0.145679</td>\n",
       "      <td>0.145679</td>\n",
       "      <td>2.039508</td>\n",
       "      <td>1.165433</td>\n",
       "      <td>3.933337</td>\n",
       "      <td>11.800012</td>\n",
       "      <td>6.118525</td>\n",
       "      <td>379.785560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>312.500000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>156.250000</td>\n",
       "      <td>156.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1093.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>468.750000</td>\n",
       "      <td>312.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>156.250000</td>\n",
       "      <td>3125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>710.059172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>236.686391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>236.686391</td>\n",
       "      <td>295.857988</td>\n",
       "      <td>236.686391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9467.455621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>2085</td>\n",
       "      <td>0.149521</td>\n",
       "      <td>0.687795</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.395655</td>\n",
       "      <td>0.011502</td>\n",
       "      <td>0.577380</td>\n",
       "      <td>2.272714</td>\n",
       "      <td>0.128818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259936</td>\n",
       "      <td>2.946707</td>\n",
       "      <td>0.055208</td>\n",
       "      <td>0.016102</td>\n",
       "      <td>0.170224</td>\n",
       "      <td>0.782108</td>\n",
       "      <td>2.866196</td>\n",
       "      <td>1.104153</td>\n",
       "      <td>0.105815</td>\n",
       "      <td>22.685736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>6.510417</td>\n",
       "      <td>34.722222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.361111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.425347</td>\n",
       "      <td>26.041667</td>\n",
       "      <td>3.255208</td>\n",
       "      <td>...</td>\n",
       "      <td>5.425347</td>\n",
       "      <td>44.487847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.085069</td>\n",
       "      <td>3.255208</td>\n",
       "      <td>18.446181</td>\n",
       "      <td>46.657986</td>\n",
       "      <td>15.190972</td>\n",
       "      <td>2.170139</td>\n",
       "      <td>929.904514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>18.903592</td>\n",
       "      <td>18.903592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>378.071834</td>\n",
       "      <td>18.903592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.807183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.710775</td>\n",
       "      <td>37.807183</td>\n",
       "      <td>245.746692</td>\n",
       "      <td>94.517958</td>\n",
       "      <td>56.710775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>516</td>\n",
       "      <td>0.075116</td>\n",
       "      <td>0.450694</td>\n",
       "      <td>0.037558</td>\n",
       "      <td>0.300463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.314524</td>\n",
       "      <td>14.121747</td>\n",
       "      <td>0.600925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713599</td>\n",
       "      <td>6.835527</td>\n",
       "      <td>0.600925</td>\n",
       "      <td>0.037558</td>\n",
       "      <td>1.051619</td>\n",
       "      <td>1.014062</td>\n",
       "      <td>5.671234</td>\n",
       "      <td>4.694730</td>\n",
       "      <td>5.258097</td>\n",
       "      <td>114.588967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.864198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.728395</td>\n",
       "      <td>462.962963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.864198</td>\n",
       "      <td>92.592593</td>\n",
       "      <td>432.098765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>648.148148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>3.698225</td>\n",
       "      <td>33.284024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.698225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.094675</td>\n",
       "      <td>136.834320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>103.550296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.568047</td>\n",
       "      <td>11.094675</td>\n",
       "      <td>22.189349</td>\n",
       "      <td>36.982249</td>\n",
       "      <td>44.378698</td>\n",
       "      <td>125.739645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>165.289256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>165.289256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.644628</td>\n",
       "      <td>495.867769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>247.933884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>495.867769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>991.735537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>565.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>443</td>\n",
       "      <td>0.407645</td>\n",
       "      <td>3.159252</td>\n",
       "      <td>0.101911</td>\n",
       "      <td>0.662424</td>\n",
       "      <td>0.101911</td>\n",
       "      <td>2.343961</td>\n",
       "      <td>12.331273</td>\n",
       "      <td>0.560512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407645</td>\n",
       "      <td>11.770761</td>\n",
       "      <td>0.509557</td>\n",
       "      <td>0.050956</td>\n",
       "      <td>2.242050</td>\n",
       "      <td>0.968158</td>\n",
       "      <td>1.732493</td>\n",
       "      <td>4.942700</td>\n",
       "      <td>4.280277</td>\n",
       "      <td>478.575687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2.704164</td>\n",
       "      <td>4.056247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.056247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.520822</td>\n",
       "      <td>77.068686</td>\n",
       "      <td>4.056247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.970795</td>\n",
       "      <td>1.352082</td>\n",
       "      <td>1.352082</td>\n",
       "      <td>6.760411</td>\n",
       "      <td>5.408329</td>\n",
       "      <td>50.027042</td>\n",
       "      <td>17.577069</td>\n",
       "      <td>25.689562</td>\n",
       "      <td>999.188751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>711</td>\n",
       "      <td>0.949515</td>\n",
       "      <td>2.749638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.720997</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>1.641870</td>\n",
       "      <td>4.727796</td>\n",
       "      <td>0.514321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375850</td>\n",
       "      <td>7.576342</td>\n",
       "      <td>0.237379</td>\n",
       "      <td>0.019782</td>\n",
       "      <td>0.356068</td>\n",
       "      <td>3.125488</td>\n",
       "      <td>8.150008</td>\n",
       "      <td>3.165052</td>\n",
       "      <td>0.276942</td>\n",
       "      <td>36.358529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>69.444444</td>\n",
       "      <td>173.611111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>173.611111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.361111</td>\n",
       "      <td>156.250000</td>\n",
       "      <td>34.722222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.083333</td>\n",
       "      <td>34.722222</td>\n",
       "      <td>121.527778</td>\n",
       "      <td>156.250000</td>\n",
       "      <td>52.083333</td>\n",
       "      <td>1024.305556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>2.519526</td>\n",
       "      <td>10.078105</td>\n",
       "      <td>2.519526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.039053</td>\n",
       "      <td>128.495843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.753842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.519526</td>\n",
       "      <td>25.195263</td>\n",
       "      <td>22.675737</td>\n",
       "      <td>75.585790</td>\n",
       "      <td>27.714790</td>\n",
       "      <td>55.429579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.925208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.476454</td>\n",
       "      <td>186.980609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>90.027701</td>\n",
       "      <td>6.925208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.925208</td>\n",
       "      <td>13.850416</td>\n",
       "      <td>27.700831</td>\n",
       "      <td>110.803324</td>\n",
       "      <td>76.177285</td>\n",
       "      <td>339.335180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>123.456790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>370.370370</td>\n",
       "      <td>617.283951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>123.456790</td>\n",
       "      <td>370.370370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>123.456790</td>\n",
       "      <td>370.370370</td>\n",
       "      <td>370.370370</td>\n",
       "      <td>246.913580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3580.246914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>444.444444</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>222.222222</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>44.444444</td>\n",
       "      <td>4400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>2.582645</td>\n",
       "      <td>5.165289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.661157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.243802</td>\n",
       "      <td>47.778926</td>\n",
       "      <td>1.291322</td>\n",
       "      <td>...</td>\n",
       "      <td>6.456612</td>\n",
       "      <td>80.061983</td>\n",
       "      <td>1.291322</td>\n",
       "      <td>1.291322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.448347</td>\n",
       "      <td>67.148760</td>\n",
       "      <td>6.456612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.006198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277.777778</td>\n",
       "      <td>1388.888889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>555.555556</td>\n",
       "      <td>1111.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4722.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>312.500000</td>\n",
       "      <td>937.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>156.250000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>156.250000</td>\n",
       "      <td>156.250000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>468.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1562.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.040816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.020408</td>\n",
       "      <td>51.020408</td>\n",
       "      <td>51.020408</td>\n",
       "      <td>306.122449</td>\n",
       "      <td>51.020408</td>\n",
       "      <td>...</td>\n",
       "      <td>51.020408</td>\n",
       "      <td>612.244898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.040816</td>\n",
       "      <td>306.122449</td>\n",
       "      <td>153.061224</td>\n",
       "      <td>51.020408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.020408</td>\n",
       "      <td>54030.612245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3333.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1111.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2222.222222</td>\n",
       "      <td>1111.111111</td>\n",
       "      <td>14444.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>493.827160</td>\n",
       "      <td>493.827160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>246.913580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>246.913580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>246.913580</td>\n",
       "      <td>864.197531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>617.283951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>340000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.020408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>293.367347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.040816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.510204</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.265306</td>\n",
       "      <td>153.061224</td>\n",
       "      <td>89.285714</td>\n",
       "      <td>1288.265306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1359 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Orphan medicine  n_trials  status_not_yet_recruiting  status_recruiting  \\\n",
       "0                   0        54                   0.000000           6.858711   \n",
       "1                   1        12                   0.000000         138.888889   \n",
       "2                   0        20                   0.000000           0.000000   \n",
       "3                   0       111                   2.434867           6.492979   \n",
       "4                   0        20                   0.000000           0.000000   \n",
       "5                   0        36                  46.296296          84.876543   \n",
       "6                   0        11                   0.000000           0.000000   \n",
       "7                   0       132                   0.573921           5.739210   \n",
       "8                   0        61                   2.687450           2.687450   \n",
       "9                   0       618                   0.288015           1.885192   \n",
       "10                  0        11                   0.000000           0.000000   \n",
       "11                  1         7                   0.000000           0.000000   \n",
       "12                  0      2085                   0.149521           0.687795   \n",
       "13                  0       132                   0.573921           5.739210   \n",
       "14                  0        55                   6.611570          39.669421   \n",
       "15                  0       262                   1.311112           4.224696   \n",
       "16                  0         8                 312.500000         625.000000   \n",
       "17                  1        13                   0.000000           0.000000   \n",
       "18                  0      2085                   0.149521           0.687795   \n",
       "19                  0        96                   6.510417          34.722222   \n",
       "20                  0        23                  18.903592          18.903592   \n",
       "21                  0       516                   0.075116           0.450694   \n",
       "22                  0        18                   0.000000           0.000000   \n",
       "23                  0        52                   3.698225          33.284024   \n",
       "24                  0        11                 165.289256           0.000000   \n",
       "25                  0       100                   2.000000           5.000000   \n",
       "26                  0       443                   0.407645           3.159252   \n",
       "27                  0        86                   2.704164           4.056247   \n",
       "28                  0       711                   0.949515           2.749638   \n",
       "29                  0        24                  69.444444         173.611111   \n",
       "...               ...       ...                        ...                ...   \n",
       "1332                0        63                   2.519526          10.078105   \n",
       "1333                0        10                   0.000000         100.000000   \n",
       "1334                0        38                   0.000000           0.000000   \n",
       "1335                0         0                   0.000000           0.000000   \n",
       "1336                0         9                   0.000000         123.456790   \n",
       "1337                0        15                   0.000000           0.000000   \n",
       "1338                1         2                   0.000000           0.000000   \n",
       "1339                0         0                   0.000000           0.000000   \n",
       "1340                0        88                   2.582645           5.165289   \n",
       "1341                0         6                   0.000000           0.000000   \n",
       "1342                0         0                   0.000000           0.000000   \n",
       "1343                1         8                   0.000000           0.000000   \n",
       "1344                1         1                   0.000000           0.000000   \n",
       "1345                0         5                   0.000000           0.000000   \n",
       "1347                0        14                   0.000000         102.040816   \n",
       "1348                0         0                   0.000000           0.000000   \n",
       "1349                0         0                   0.000000           0.000000   \n",
       "1350                1         2                   0.000000           0.000000   \n",
       "1351                1         1                   0.000000           0.000000   \n",
       "1352                1         1                   0.000000           0.000000   \n",
       "1353                0         3                   0.000000           0.000000   \n",
       "1354                0         4                   0.000000           0.000000   \n",
       "1355                0         9                   0.000000           0.000000   \n",
       "1356                0         2                   0.000000           0.000000   \n",
       "1357                0         5                   0.000000         400.000000   \n",
       "1358                1         0                   0.000000           0.000000   \n",
       "1359                0         0                   0.000000           0.000000   \n",
       "1360                0         2                   0.000000           0.000000   \n",
       "1361                1         4                   0.000000           0.000000   \n",
       "1362                0        28                   0.000000          51.020408   \n",
       "\n",
       "      status_enrolling_by_invitation  status_active_not_recruiting  \\\n",
       "0                           0.000000                      3.429355   \n",
       "1                           0.000000                     69.444444   \n",
       "2                           0.000000                      0.000000   \n",
       "3                           0.000000                      5.681357   \n",
       "4                           0.000000                      0.000000   \n",
       "5                           0.000000                     15.432099   \n",
       "6                           0.000000                      0.000000   \n",
       "7                           0.000000                      5.739210   \n",
       "8                           0.000000                      5.374899   \n",
       "9                           0.052366                      0.837863   \n",
       "10                          0.000000                     82.644628   \n",
       "11                          0.000000                      0.000000   \n",
       "12                          0.006901                      0.395655   \n",
       "13                          0.000000                      5.739210   \n",
       "14                          3.305785                     33.057851   \n",
       "15                          0.000000                      1.748150   \n",
       "16                          0.000000                      0.000000   \n",
       "17                          0.000000                      0.000000   \n",
       "18                          0.006901                      0.395655   \n",
       "19                          0.000000                     17.361111   \n",
       "20                          0.000000                      0.000000   \n",
       "21                          0.037558                      0.300463   \n",
       "22                          0.000000                     30.864198   \n",
       "23                          0.000000                      3.698225   \n",
       "24                          0.000000                    165.289256   \n",
       "25                          0.000000                      6.000000   \n",
       "26                          0.101911                      0.662424   \n",
       "27                          0.000000                      4.056247   \n",
       "28                          0.000000                      1.720997   \n",
       "29                          0.000000                      0.000000   \n",
       "...                              ...                           ...   \n",
       "1332                        2.519526                      0.000000   \n",
       "1333                        0.000000                      0.000000   \n",
       "1334                        0.000000                      6.925208   \n",
       "1335                        0.000000                      0.000000   \n",
       "1336                        0.000000                      0.000000   \n",
       "1337                       44.444444                      0.000000   \n",
       "1338                        0.000000                      0.000000   \n",
       "1339                        0.000000                      0.000000   \n",
       "1340                        0.000000                     20.661157   \n",
       "1341                        0.000000                      0.000000   \n",
       "1342                        0.000000                      0.000000   \n",
       "1343                        0.000000                      0.000000   \n",
       "1344                        0.000000                      0.000000   \n",
       "1345                        0.000000                      0.000000   \n",
       "1347                        0.000000                     51.020408   \n",
       "1348                        0.000000                      0.000000   \n",
       "1349                        0.000000                      0.000000   \n",
       "1350                        0.000000                      0.000000   \n",
       "1351                        0.000000                      0.000000   \n",
       "1352                        0.000000                      0.000000   \n",
       "1353                        0.000000                      0.000000   \n",
       "1354                        0.000000                      0.000000   \n",
       "1355                        0.000000                      0.000000   \n",
       "1356                        0.000000                      0.000000   \n",
       "1357                        0.000000                    400.000000   \n",
       "1358                        0.000000                      0.000000   \n",
       "1359                        0.000000                      0.000000   \n",
       "1360                        0.000000                      0.000000   \n",
       "1361                        0.000000                      0.000000   \n",
       "1362                        0.000000                      0.000000   \n",
       "\n",
       "      status_suspended  status_terminated  status_completed  status_withdrawn  \\\n",
       "0             0.000000          10.288066        147.462277         10.288066   \n",
       "1             0.000000           0.000000        625.000000          0.000000   \n",
       "2             0.000000           0.000000        450.000000         50.000000   \n",
       "3             0.000000           9.739469         51.943836          2.434867   \n",
       "4             0.000000           0.000000        450.000000         50.000000   \n",
       "5             0.000000           0.000000        108.024691          7.716049   \n",
       "6             0.000000           0.000000        909.090909          0.000000   \n",
       "7             0.000000           2.295684         51.652893          2.869605   \n",
       "8             0.000000          13.437248        118.247783          5.374899   \n",
       "9             0.026183           1.073512         10.001990          0.366565   \n",
       "10            0.000000          82.644628        661.157025          0.000000   \n",
       "11            0.000000           0.000000        816.326531          0.000000   \n",
       "12            0.011502           0.577380          2.272714          0.128818   \n",
       "13            0.000000           2.295684         51.652893          2.869605   \n",
       "14            0.000000          16.528926         62.809917          9.917355   \n",
       "15            0.145679           1.165433         25.348173          0.728396   \n",
       "16            0.000000         156.250000        156.250000          0.000000   \n",
       "17            0.000000           0.000000        710.059172          0.000000   \n",
       "18            0.011502           0.577380          2.272714          0.128818   \n",
       "19            0.000000           5.425347         26.041667          3.255208   \n",
       "20            0.000000           0.000000        378.071834         18.903592   \n",
       "21            0.000000           1.314524         14.121747          0.600925   \n",
       "22            0.000000          61.728395        462.962963          0.000000   \n",
       "23            0.000000          11.094675        136.834320          0.000000   \n",
       "24            0.000000          82.644628        495.867769          0.000000   \n",
       "25            0.000000           7.000000         71.000000          3.000000   \n",
       "26            0.101911           2.343961         12.331273          0.560512   \n",
       "27            0.000000          13.520822         77.068686          4.056247   \n",
       "28            0.019782           1.641870          4.727796          0.514321   \n",
       "29            0.000000           0.000000        173.611111          0.000000   \n",
       "...                ...                ...               ...               ...   \n",
       "1332          0.000000           5.039053        128.495843          0.000000   \n",
       "1333          0.000000           0.000000        900.000000          0.000000   \n",
       "1334          0.000000          48.476454        186.980609          0.000000   \n",
       "1335          0.000000           0.000000          0.000000          0.000000   \n",
       "1336          0.000000         370.370370        617.283951          0.000000   \n",
       "1337          0.000000          88.888889        444.444444         44.444444   \n",
       "1338          0.000000        2500.000000       2500.000000          0.000000   \n",
       "1339          0.000000           0.000000          0.000000          0.000000   \n",
       "1340          0.000000          23.243802         47.778926          1.291322   \n",
       "1341          0.000000         277.777778       1388.888889          0.000000   \n",
       "1342          0.000000           0.000000          0.000000          0.000000   \n",
       "1343          0.000000         312.500000        937.500000          0.000000   \n",
       "1344          0.000000           0.000000      10000.000000          0.000000   \n",
       "1345          0.000000           0.000000       2000.000000          0.000000   \n",
       "1347         51.020408          51.020408        306.122449         51.020408   \n",
       "1348          0.000000           0.000000          0.000000          0.000000   \n",
       "1349          0.000000           0.000000          0.000000          0.000000   \n",
       "1350          0.000000           0.000000       5000.000000          0.000000   \n",
       "1351          0.000000           0.000000      10000.000000          0.000000   \n",
       "1352          0.000000           0.000000          0.000000          0.000000   \n",
       "1353          0.000000           0.000000       3333.333333          0.000000   \n",
       "1354          0.000000           0.000000       2500.000000          0.000000   \n",
       "1355          0.000000         493.827160        493.827160          0.000000   \n",
       "1356          0.000000        2500.000000       2500.000000          0.000000   \n",
       "1357          0.000000           0.000000       1200.000000          0.000000   \n",
       "1358          0.000000           0.000000          0.000000          0.000000   \n",
       "1359          0.000000           0.000000          0.000000          0.000000   \n",
       "1360          0.000000        2500.000000       2500.000000          0.000000   \n",
       "1361          0.000000         625.000000          0.000000          0.000000   \n",
       "1362          0.000000           0.000000        293.367347          0.000000   \n",
       "\n",
       "      ...      org_nih     org_other  org_other_gov  phase_early_1  \\\n",
       "0     ...     0.000000     41.152263       6.858711       0.000000   \n",
       "1     ...     0.000000    138.888889       0.000000       0.000000   \n",
       "2     ...     0.000000     75.000000       0.000000       0.000000   \n",
       "3     ...    10.551092     43.015989       3.246490       0.811622   \n",
       "4     ...     0.000000     75.000000       0.000000       0.000000   \n",
       "5     ...     0.000000    108.024691       0.000000       7.716049   \n",
       "6     ...   826.446281     82.644628       0.000000       0.000000   \n",
       "7     ...     0.573921     39.600551       1.147842       0.000000   \n",
       "8     ...     2.687450     48.374093       2.687450       0.000000   \n",
       "9     ...     0.130916      6.283973       0.130916       0.026183   \n",
       "10    ...    82.644628    247.933884       0.000000       0.000000   \n",
       "11    ...     0.000000      0.000000       0.000000       0.000000   \n",
       "12    ...     0.259936      2.946707       0.055208       0.016102   \n",
       "13    ...     0.573921     39.600551       1.147842       0.000000   \n",
       "14    ...     0.000000    132.231405       0.000000       0.000000   \n",
       "15    ...     0.145679     14.276557       0.145679       0.145679   \n",
       "16    ...     0.000000   1093.750000       0.000000       0.000000   \n",
       "17    ...     0.000000    236.686391       0.000000       0.000000   \n",
       "18    ...     0.259936      2.946707       0.055208       0.016102   \n",
       "19    ...     5.425347     44.487847       0.000000       1.085069   \n",
       "20    ...     0.000000     37.807183       0.000000       0.000000   \n",
       "21    ...     0.713599      6.835527       0.600925       0.037558   \n",
       "22    ...     0.000000      0.000000       0.000000       0.000000   \n",
       "23    ...     0.000000    103.550296       0.000000       0.000000   \n",
       "24    ...     0.000000      0.000000       0.000000       0.000000   \n",
       "25    ...     2.000000     35.000000       0.000000       0.000000   \n",
       "26    ...     0.407645     11.770761       0.509557       0.050956   \n",
       "27    ...     0.000000     45.970795       1.352082       1.352082   \n",
       "28    ...     0.375850      7.576342       0.237379       0.019782   \n",
       "29    ...    17.361111    156.250000      34.722222       0.000000   \n",
       "...   ...          ...           ...            ...            ...   \n",
       "1332  ...     0.000000     32.753842       0.000000       0.000000   \n",
       "1333  ...     0.000000    100.000000       0.000000       0.000000   \n",
       "1334  ...     0.000000     90.027701       6.925208       0.000000   \n",
       "1335  ...     0.000000      0.000000       0.000000       0.000000   \n",
       "1336  ...   123.456790    370.370370       0.000000       0.000000   \n",
       "1337  ...     0.000000    133.333333       0.000000       0.000000   \n",
       "1338  ...     0.000000      0.000000       0.000000       0.000000   \n",
       "1339  ...     0.000000      0.000000       0.000000       0.000000   \n",
       "1340  ...     6.456612     80.061983       1.291322       1.291322   \n",
       "1341  ...     0.000000      0.000000       0.000000       0.000000   \n",
       "1342  ...     0.000000      0.000000       0.000000       0.000000   \n",
       "1343  ...   156.250000    625.000000       0.000000       0.000000   \n",
       "1344  ...     0.000000      0.000000       0.000000       0.000000   \n",
       "1345  ...     0.000000      0.000000       0.000000       0.000000   \n",
       "1347  ...    51.020408    612.244898       0.000000     102.040816   \n",
       "1348  ...     0.000000      0.000000       0.000000       0.000000   \n",
       "1349  ...     0.000000      0.000000       0.000000       0.000000   \n",
       "1350  ...     0.000000      0.000000       0.000000       0.000000   \n",
       "1351  ...     0.000000  10000.000000       0.000000       0.000000   \n",
       "1352  ...     0.000000  10000.000000       0.000000       0.000000   \n",
       "1353  ...     0.000000      0.000000    1111.111111       0.000000   \n",
       "1354  ...     0.000000      0.000000       0.000000       0.000000   \n",
       "1355  ...     0.000000    246.913580       0.000000       0.000000   \n",
       "1356  ...     0.000000      0.000000       0.000000       0.000000   \n",
       "1357  ...     0.000000    800.000000       0.000000       0.000000   \n",
       "1358  ...     0.000000      0.000000       0.000000       0.000000   \n",
       "1359  ...     0.000000      0.000000       0.000000       0.000000   \n",
       "1360  ...     0.000000   2500.000000       0.000000       0.000000   \n",
       "1361  ...  1875.000000      0.000000       0.000000       0.000000   \n",
       "1362  ...     0.000000    102.040816       0.000000       0.000000   \n",
       "\n",
       "      phase_not_applicable     phase_1       phase_2       phase_3  \\\n",
       "0                 6.858711    3.429355      6.858711     58.299040   \n",
       "1                 0.000000   69.444444    277.777778    208.333333   \n",
       "2                50.000000    0.000000      0.000000    125.000000   \n",
       "3                 0.000000   27.595163     52.755458     17.044071   \n",
       "4                50.000000    0.000000      0.000000    125.000000   \n",
       "5                38.580247   15.432099     84.876543     92.592593   \n",
       "6                 0.000000  909.090909      0.000000      0.000000   \n",
       "7                 7.460973    6.313131     19.513315     15.495868   \n",
       "8                21.499597    2.687450     29.561946     56.436442   \n",
       "9                 0.942596    0.497481      1.806642      4.634430   \n",
       "10                0.000000  165.289256    578.512397     82.644628   \n",
       "11                0.000000  204.081633    204.081633   1020.408163   \n",
       "12                0.170224    0.782108      2.866196      1.104153   \n",
       "13                7.460973    6.313131     19.513315     15.495868   \n",
       "14                3.305785   26.446281    109.090909     19.834711   \n",
       "15                2.039508    1.165433      3.933337     11.800012   \n",
       "16                0.000000  468.750000    312.500000      0.000000   \n",
       "17                0.000000  236.686391    295.857988    236.686391   \n",
       "18                0.170224    0.782108      2.866196      1.104153   \n",
       "19                3.255208   18.446181     46.657986     15.190972   \n",
       "20                0.000000   56.710775     37.807183    245.746692   \n",
       "21                1.051619    1.014062      5.671234      4.694730   \n",
       "22                0.000000   30.864198     92.592593    432.098765   \n",
       "23               66.568047   11.094675     22.189349     36.982249   \n",
       "24                0.000000  247.933884      0.000000    495.867769   \n",
       "25                3.000000   13.000000     47.000000     25.000000   \n",
       "26                2.242050    0.968158      1.732493      4.942700   \n",
       "27                6.760411    5.408329     50.027042     17.577069   \n",
       "28                0.356068    3.125488      8.150008      3.165052   \n",
       "29               52.083333   34.722222    121.527778    156.250000   \n",
       "...                    ...         ...           ...           ...   \n",
       "1332              2.519526   25.195263     22.675737     75.585790   \n",
       "1333              0.000000    0.000000    500.000000    700.000000   \n",
       "1334              6.925208   13.850416     27.700831    110.803324   \n",
       "1335              0.000000    0.000000      0.000000      0.000000   \n",
       "1336            123.456790  370.370370    370.370370    246.913580   \n",
       "1337              0.000000    0.000000    222.222222    400.000000   \n",
       "1338              0.000000    0.000000   2500.000000   2500.000000   \n",
       "1339              0.000000    0.000000      0.000000      0.000000   \n",
       "1340              0.000000   37.448347     67.148760      6.456612   \n",
       "1341              0.000000    0.000000    555.555556   1111.111111   \n",
       "1342              0.000000    0.000000      0.000000      0.000000   \n",
       "1343            156.250000  156.250000    625.000000    468.750000   \n",
       "1344              0.000000    0.000000      0.000000  10000.000000   \n",
       "1345              0.000000    0.000000      0.000000   2000.000000   \n",
       "1347            306.122449  153.061224     51.020408      0.000000   \n",
       "1348              0.000000    0.000000      0.000000      0.000000   \n",
       "1349              0.000000    0.000000      0.000000      0.000000   \n",
       "1350              0.000000    0.000000      0.000000   5000.000000   \n",
       "1351              0.000000    0.000000  10000.000000      0.000000   \n",
       "1352              0.000000    0.000000      0.000000      0.000000   \n",
       "1353              0.000000    0.000000      0.000000   2222.222222   \n",
       "1354              0.000000    0.000000      0.000000   2500.000000   \n",
       "1355            246.913580    0.000000    246.913580    864.197531   \n",
       "1356              0.000000    0.000000      0.000000   5000.000000   \n",
       "1357            400.000000    0.000000      0.000000   1600.000000   \n",
       "1358              0.000000    0.000000      0.000000      0.000000   \n",
       "1359              0.000000    0.000000      0.000000      0.000000   \n",
       "1360           2500.000000    0.000000   2500.000000      0.000000   \n",
       "1361              0.000000    0.000000    625.000000   2500.000000   \n",
       "1362             25.510204    0.000000     38.265306    153.061224   \n",
       "\n",
       "          phase_4     pm_results  \n",
       "0      102.880658     150.891632  \n",
       "1        0.000000     763.888889  \n",
       "2      300.000000     900.000000  \n",
       "3        0.000000     424.478533  \n",
       "4      300.000000     900.000000  \n",
       "5       30.864198     408.950617  \n",
       "6        0.000000     826.446281  \n",
       "7       19.513315     808.080808  \n",
       "8       45.686643    2112.335394  \n",
       "9        3.220536     154.192981  \n",
       "10     165.289256   13801.652893  \n",
       "11     204.081633    5918.367347  \n",
       "12       0.105815      22.743244  \n",
       "13      19.513315     810.376492  \n",
       "14      16.528926    1712.396694  \n",
       "15       6.118525     379.785560  \n",
       "16     156.250000    3125.000000  \n",
       "17       0.000000    9467.455621  \n",
       "18       0.105815      22.685736  \n",
       "19       2.170139     929.904514  \n",
       "20      94.517958      56.710775  \n",
       "21       5.258097     114.588967  \n",
       "22       0.000000     648.148148  \n",
       "23      44.378698     125.739645  \n",
       "24       0.000000     991.735537  \n",
       "25      10.000000     565.000000  \n",
       "26       4.280277     478.575687  \n",
       "27      25.689562     999.188751  \n",
       "28       0.276942      36.358529  \n",
       "29      52.083333    1024.305556  \n",
       "...           ...            ...  \n",
       "1332    27.714790      55.429579  \n",
       "1333     0.000000     600.000000  \n",
       "1334    76.177285     339.335180  \n",
       "1335     0.000000       0.000000  \n",
       "1336     0.000000    3580.246914  \n",
       "1337    44.444444    4400.000000  \n",
       "1338     0.000000   10000.000000  \n",
       "1339     0.000000       0.000000  \n",
       "1340     0.000000     133.006198  \n",
       "1341     0.000000    4722.222222  \n",
       "1342     0.000000       0.000000  \n",
       "1343     0.000000    1562.500000  \n",
       "1344     0.000000       0.000000  \n",
       "1345     0.000000    1200.000000  \n",
       "1347    51.020408   54030.612245  \n",
       "1348     0.000000       0.000000  \n",
       "1349     0.000000       0.000000  \n",
       "1350     0.000000    2500.000000  \n",
       "1351     0.000000  120000.000000  \n",
       "1352     0.000000   30000.000000  \n",
       "1353  1111.111111   14444.444444  \n",
       "1354     0.000000   23750.000000  \n",
       "1355     0.000000     617.283951  \n",
       "1356     0.000000   45000.000000  \n",
       "1357     0.000000    3600.000000  \n",
       "1358     0.000000       0.000000  \n",
       "1359     0.000000       0.000000  \n",
       "1360     0.000000  340000.000000  \n",
       "1361     0.000000   13750.000000  \n",
       "1362    89.285714    1288.265306  \n",
       "\n",
       "[1359 rows x 25 columns]"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tranform= FunctionTransformer(lambda x: x)\n",
    "\n",
    "test_pipe= Pipeline([\n",
    "    ('percentage_transformation', percent),\n",
    "    ('scaler', MinMaxScaler())])\n",
    "test_pipe.fit(X,y)\n",
    "test_pipe.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'n_trials'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'n_trials'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-378-29899f3afa33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     ('best_model', KNeighborsClassifier(leaf_size=10, n_jobs=-1, p=1, weights='distance'))])\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mnumerical_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    328\u001b[0m         \"\"\"\n\u001b[0;32m    329\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    332\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    297\u001b[0m             \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[1;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[0;32m    465\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[0;32m    466\u001b[0m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[1;32m--> 467\u001b[1;33m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[0m\u001b[0;32m    468\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"Expected 2D array, got 1D array instead\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \"\"\"\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkw_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X, func, kw_args)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_identity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkw_args\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkw_args\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-378-29899f3afa33>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(df_numerical)\u001b[0m\n\u001b[0;32m     15\u001b[0m              'phase_2','Authorisation status']\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mpercent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFunctionTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mdf_numerical\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpercentage_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_numerical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpercent_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'n_trials'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m preprocessing= ColumnTransformer([\n",
      "\u001b[1;32m<ipython-input-373-bc3e8a7d27a2>\u001b[0m in \u001b[0;36mpercentage_columns\u001b[1;34m(df, column_list, column_total)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpercentage_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumn_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumn_total\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumn_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_total\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucia\\.venvs\\lewagon\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'n_trials'"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "percent_columns= ['status_not_yet_recruiting', 'status_recruiting',\n",
    "       'status_enrolling_by_invitation', 'status_active_not_recruiting',\n",
    "       'status_suspended', 'status_terminated', 'status_completed',\n",
    "       'status_withdrawn', 'status_unknown', 'org_fed', 'org_indiv',\n",
    "       'org_industry', 'org_network', 'org_nih', 'org_other', 'org_other_gov',\n",
    "       'phase_early_1', 'phase_not_applicable', 'phase_1', 'phase_2',\n",
    "       'phase_3', 'phase_4', 'pm_results']\n",
    "top_columns= ['org_industry',  'n_trials',  'phase_4',\n",
    "             'org_other', 'status_completed', 'status_recruiting',\n",
    "             'phase_3',  'pm_results', 'status_not_yet_recruiting',\n",
    "             'phase_2','Authorisation status']\n",
    "\n",
    "percent=FunctionTransformer(lambda df_numerical: percentage_columns(df_numerical, percent_columns, 'n_trials'))\n",
    "\n",
    "preprocessing= ColumnTransformer([\n",
    "    ('percentage_transformation', percent, percent_columns),\n",
    "    ('scaler', MinMaxScaler(), percent_columns)])\n",
    "\n",
    "numerical_pipe= Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('best_model', KNeighborsClassifier(leaf_size=10, n_jobs=-1, p=1, weights='distance'))])\n",
    "\n",
    "numerical_pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipe.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
